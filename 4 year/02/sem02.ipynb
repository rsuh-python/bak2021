{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "HWfmZei5t_8I"
   },
   "source": [
    "### natasha"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "Fw52LhAct9Tg"
   },
   "outputs": [],
   "source": [
    "!pip install natasha"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "8VqX_VxouI-q"
   },
   "source": [
    "Морфосинтаксический парсинг"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "executionInfo": {
     "elapsed": 253,
     "status": "ok",
     "timestamp": 1663154496060,
     "user": {
      "displayName": "Alexandra Ivoylova",
      "userId": "06069991353189522669"
     },
     "user_tz": -180
    },
    "id": "S5k9Wlz9uK7M"
   },
   "outputs": [],
   "source": [
    "from natasha import (\n",
    "    Segmenter,\n",
    "    \n",
    "    NewsEmbedding,\n",
    "    NewsMorphTagger,\n",
    "    NewsSyntaxParser,\n",
    "    \n",
    "    Doc\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "ciOkGldHuLgB"
   },
   "outputs": [],
   "source": [
    "segmenter = Segmenter()  # токенизация и разделение на предложения\n",
    "emb = NewsEmbedding()  # эмбеддинги\n",
    "morph_tagger = NewsMorphTagger(emb)  # морфология\n",
    "syntax_parser = NewsSyntaxParser(emb) # синтаксис\n",
    "\n",
    "text = '29 марта 2017 года правительство Великобритании инициировало процедуру выхода в соответствии со статьёй 50 Договора о Европейском союзе; первоначально планировалось, что Великобритания покинет Европейский союз через два года, 29 марта 2019 года в 23:00 по Гринвичу.'\n",
    "doc = Doc(text)\n",
    "\n",
    "doc.segment(segmenter)\n",
    "doc.tag_morph(morph_tagger)\n",
    "doc.parse_syntax(syntax_parser)\n",
    "sent = doc.sents[0]\n",
    "sent.morph.print()\n",
    "sent.syntax.print()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "YPCVWdB1ujFp"
   },
   "source": [
    "Распознание именованных сущностей"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "AaTUTjyMuikI"
   },
   "outputs": [],
   "source": [
    "from natasha import NewsNERTagger\n",
    "\n",
    "ner_tagger = NewsNERTagger(emb)\n",
    "doc.tag_ner(ner_tagger)\n",
    "doc.ner.print()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Log6uopyux7n"
   },
   "source": [
    "Лемматизация"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "RNSGZViPuuJd"
   },
   "outputs": [],
   "source": [
    "from natasha import MorphVocab\n",
    "\n",
    "morph_vocab = MorphVocab()\n",
    "\n",
    "for token in doc.tokens:\n",
    "  token.lemmatize(morph_vocab)\n",
    "  print(token.lemma)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "o1dqpS_Hu3OT"
   },
   "source": [
    "Нормализация именованных сущностей"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "gqmxRFqbu2m8"
   },
   "outputs": [],
   "source": [
    "for span in doc.spans:\n",
    "    span.normalize(morph_vocab)\n",
    "   \n",
    "{_.text: _.normal for _ in doc.spans}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "lg1ZZ8BAxM6g"
   },
   "source": [
    "Упражнения\n",
    "\n",
    "- Возьмите любой достаточно длинный новостной текст, извлеките из него все именованные сущности и нормализуйте их. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "BplzY__-xWb4"
   },
   "outputs": [],
   "source": [
    "# your code here"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "mcb7BQ4BxYIn"
   },
   "source": [
    "- Постройте дерево зависимостей для одного и того же предложения в natasha и spacy или corpy (придется вручную записать файл .conll и отправить его содержимое в арборатор, например: как это сделать, уточните в лекции 6 за прошлый семестр). Сравните, что вам больше нравится. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "idrup3gKyB8C"
   },
   "outputs": [],
   "source": [
    "# your code here"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "5GU9unbnvJXP"
   },
   "source": [
    "### Stanza"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "eKwCF6UOvRCh"
   },
   "outputs": [],
   "source": [
    "!pip install stanza"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Zv7BrtxEvUwY"
   },
   "source": [
    "Загрузка моделей"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "executionInfo": {
     "elapsed": 2995,
     "status": "ok",
     "timestamp": 1663154625797,
     "user": {
      "displayName": "Alexandra Ivoylova",
      "userId": "06069991353189522669"
     },
     "user_tz": -180
    },
    "id": "8UtSgSntvXro"
   },
   "outputs": [],
   "source": [
    "import stanza"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "P7VKLnRkvZd4"
   },
   "outputs": [],
   "source": [
    "nlp_ru = stanza.Pipeline(lang='ru')\n",
    "nlp_en = stanza.Pipeline(lang='en', processors='tokenize, pos, constituency')\n",
    "nlp_fr = stanza.Pipeline(lang='fr', processors='tokenize, mwt')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "dUR7LXjmvtpn"
   },
   "source": [
    "Токенизация, сегментация по предложениям"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "executionInfo": {
     "elapsed": 2242,
     "status": "ok",
     "timestamp": 1663154958031,
     "user": {
      "displayName": "Alexandra Ivoylova",
      "userId": "06069991353189522669"
     },
     "user_tz": -180
    },
    "id": "Db8CYc_SvtIX"
   },
   "outputs": [],
   "source": [
    "text = '''Архитектура Византии — совокупность традиций строительства и архитектуры в поздней Римской империи и в Византии в период с начала IV века по середину XV века. В качестве отдельных направлений исследования выделяют религиозную архитектуру Византии, византийскую фортификацию и гражданское строительство, включающее дворцы, общественные сооружения и частные дома. Также в рамках данной дисциплины изучают традиции строительного ремесла и декоративного искусства.'''\n",
    "\n",
    "doc = nlp_ru(text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 273,
     "status": "ok",
     "timestamp": 1663154817857,
     "user": {
      "displayName": "Alexandra Ivoylova",
      "userId": "06069991353189522669"
     },
     "user_tz": -180
    },
    "id": "MMT0yrtGv3wP",
    "outputId": "2e4e3a15-9345-47c7-ed71-e4c8fc17dc2b"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Архитектура Византии — совокупность традиций строительства и архитектуры в поздней Римской империи и в Византии в период с начала IV века по середину XV века.\n",
      "В качестве отдельных направлений исследования выделяют религиозную архитектуру Византии, византийскую фортификацию и гражданское строительство, включающее дворцы, общественные сооружения и частные дома.\n",
      "Также в рамках данной дисциплины изучают традиции строительного ремесла и декоративного искусства.\n"
     ]
    }
   ],
   "source": [
    "print(*[sentence.text for sentence in doc.sentences], sep='\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "IxBb4XOMwJdf"
   },
   "outputs": [],
   "source": [
    "for i, sentence in enumerate(doc.sentences):\n",
    "  print(f'====== Sentence {i+1} tokens =======')\n",
    "  print(*[f'id: {token.id}\\ttext: {token.text}' for token in sentence.tokens], sep='\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "i2cRJqFSwO-v"
   },
   "outputs": [],
   "source": [
    "text_fr = '''Il est révélé par les romans Extension du domaine de la lutte (1994) et, surtout, Les Particules élémentaires (1998), qui le fait connaître d'un large public.'''\n",
    "\n",
    "doc_fr = nlp_fr(text_fr)\n",
    "for token in doc_fr.sentences[0].tokens:\n",
    "    print(f'token: {token.text}\\twords: {\", \".join([word.text for word in token.words])}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "HlS7SKLUwetI"
   },
   "source": [
    "Лемматизация"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "Fh6HPJn2wgcp"
   },
   "outputs": [],
   "source": [
    "print(*[f'word: {word.text+\" \"}\\tlemma: {word.lemma}' for sent in doc.sentences for word in sent.words], sep='\\n')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "5SsW-5MFwupQ"
   },
   "source": [
    "Морфопарсинг"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "Z2wxiB8NwtYf"
   },
   "outputs": [],
   "source": [
    "print(*[f'word: {word.text}\\tupos: {word.upos}\\txpos: {word.xpos}\\tfeats: {word.feats if word.feats else \"_\"}' for sent in doc.sentences for word in sent.words], sep='\\n')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "bKZwX5l8wy6Q"
   },
   "source": [
    "Парсинг синтаксических зависимостей"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "w11Jqo6Fwx14"
   },
   "outputs": [],
   "source": [
    "print(*[f'id: {word.id}\\tword: {word.text}\\thead id: {word.head}\\thead: {sent.words[word.head-1].text if word.head > 0 else \"root\"}\\tdeprel: {word.deprel}' for sent in doc.sentences for word in sent.words], sep='\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "k7zTW3sJw27A"
   },
   "outputs": [],
   "source": [
    "doc.sentences[0].print_dependencies()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "8-1cXBtWw5K4"
   },
   "source": [
    "Парсинг составляющих (для русского недоступен)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "5KGb8sV6w6lo"
   },
   "outputs": [],
   "source": [
    "doc_en = nlp_en('This is a sentence for parsing constituencies.')\n",
    "\n",
    "for sentence in doc_en.sentences:\n",
    "    print(sentence.constituency)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "xmZnXnpiycdY"
   },
   "source": [
    "**Упражнения**\n",
    "\n",
    "Сделайте токенизацию и морфосинтаксический парсинг для одного предложения на любом языке (доступность моделей для вашего языка можно посмотреть [здесь](https://stanfordnlp.github.io/stanza/available_models.html)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "FmFSXvteys1u"
   },
   "outputs": [],
   "source": [
    "# your code here"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "authorship_tag": "ABX9TyNltOW1qVSOHhDinlvQSfFt",
   "collapsed_sections": [],
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
